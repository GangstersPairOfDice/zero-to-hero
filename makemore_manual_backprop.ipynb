{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd61296b-5a39-404b-98af-b13ecbfc79df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from tinygrad import Tensor\n",
    "from tinygrad import Device\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "\n",
    "Device.DEFAULT = \"GPU\" # set to tinygrad backend to GPU since METAL doesn't work on older intel macs\n",
    "print(Device.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d4dd0c-794d-47d5-be25-1af614ba3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first five moves in dataset:\n",
      "['10,000,000 Volt Thunderbolt', 'Absorb', 'Accelerock', 'Acid', 'Acid Armor']\n",
      "total number of moves: 724\n"
     ]
    }
   ],
   "source": [
    "# import and clean pokemon name data\n",
    "\n",
    "import csv\n",
    "\n",
    "moves = []\n",
    "\n",
    "with open('Pokemon_moves.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader) # skips header row\n",
    "    for row in reader:\n",
    "        if len(row) > 1:\n",
    "            moves.append(row[0])\n",
    "\n",
    "print(f'first five moves in dataset:')\n",
    "print(moves[:5])\n",
    "print(f'total number of moves: {len(moves)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f8fd77-f684-425a-a937-051599a29944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ' ', 2: \"'\", 3: ',', 4: '-', 5: '0', 6: '1', 7: '2', 8: '7', 9: 'A', 10: 'B', 11: 'C', 12: 'D', 13: 'E', 14: 'F', 15: 'G', 16: 'H', 17: 'I', 18: 'J', 19: 'K', 20: 'L', 21: 'M', 22: 'N', 23: 'O', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'T', 29: 'U', 30: 'V', 31: 'W', 32: 'X', 33: 'Y', 34: 'Z', 35: 'a', 36: 'b', 37: 'c', 38: 'd', 39: 'e', 40: 'f', 41: 'g', 42: 'h', 43: 'i', 44: 'k', 45: 'l', 46: 'm', 47: 'n', 48: 'o', 49: 'p', 50: 'q', 51: 'r', 52: 's', 53: 't', 54: 'u', 55: 'v', 56: 'w', 57: 'x', 58: 'y', 59: 'z', 0: '.'}\n",
      "num_unique_chars = 60\n",
      "all_chars =  {\"'\", 'v', 'F', 'e', ',', 'o', 'G', 'A', 'c', 'S', 'k', 'w', 's', 'l', 'I', 'z', 'p', 'r', '-', 'B', 'O', 'K', 'M', 'H', 'P', 'V', 'x', 'Q', 'D', 'W', 'y', 'q', 'E', 't', 'C', 'h', ' ', 'J', 'U', 'X', 'g', 'N', '0', 'T', '1', 'b', 'Z', 'Y', 'a', 'i', 'f', 'n', 'm', '.', 'd', 'R', 'u', 'L', '7', '2'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(moves))))\n",
    "# stoi = string to int, itos = int to string\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0 # set . as end char, since all other end chars are already used\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)\n",
    "\n",
    "# finding # of unique chars so we can set our Tensor dim. later\n",
    "all_chars = set(''.join(stoi))\n",
    "num_unique_chars = len(all_chars)\n",
    "\n",
    "print('num_unique_chars =', num_unique_chars)\n",
    "print('all_chars = ', all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44e3863-509a-48ec-8d44-92200f204f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6463, 8) (6463,)\n",
      "(753, 8) (753,)\n",
      "(820, 8) (820,)\n"
     ]
    }
   ],
   "source": [
    "# build the dataset ( in terms of train, val, and test sets )\n",
    "\n",
    "block_size = 8 # context length: how many chars do we take to predict the next on?\n",
    "\n",
    "def build_dataset(moves):\n",
    "    \n",
    "    X, Y = [], [] # X = inputs, Y = labels\n",
    "    \n",
    "    for n in moves:\n",
    "    \n",
    "        #print(n)\n",
    "        context = [0] * block_size # start with padded context\n",
    "    \n",
    "        # iter over all chars\n",
    "        for ch in n + '.':\n",
    "            ix = stoi[ch] # get char in sequence\n",
    "            X.append(context) # stores current running context\n",
    "            Y.append(ix) # stores current char\n",
    "            #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "            context = context[1:] + [ix] # crop and append (rolling window of context)\n",
    "    \n",
    "    X = Tensor(X)\n",
    "    Y = Tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.shuffle(moves)\n",
    "n1 = int(0.8*len(moves))\n",
    "n2 = int(0.9*len(moves))\n",
    "\n",
    "Xtr, Ytr = build_dataset(moves[:n1])\n",
    "Xdev, Ydev = build_dataset(moves[n1:n2])\n",
    "Xte, Yte = build_dataset(moves[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3592c530-9c43-487d-bd87-8b81477c1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "### boilerplate done, now we get to the action: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5b4d5-3916-4174-8c27-aaff4cb58701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to tinygrad gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = Tensor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
